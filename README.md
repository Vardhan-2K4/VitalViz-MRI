# ğŸ§  VitalViz-MRI - VR Medical Imaging Visualizer

An innovative **Virtual Reality Health Viewer** that transforms medical brain imaging data into interactive 3D visualizations. Built for healthcare professionals and medical students to explore MRI brain models through immersive VR experiences and gesture-based controls.


- **ğŸ§  Medical Brain Model Visualization**: Convert `.nii` neuroimaging files to interactive `.ply` 3D models
- **ğŸ¥½ VR & Traditional Viewing Modes**: Experience brain models in both VR and standard 3D environments
- **ğŸ‘‹ Gesture-Based Controls**: Navigate and manipulate models using hand gestures via MediaPipe
- **âš¡ Real-Time Processing**: Live updates and instant model transformations
- **ğŸ”„ Multi-Format Support**: Handle various medical imaging file formats
- **ğŸ“± Cross-Platform Compatible**: Works across different devices and browsers
- **ğŸ¯ Medical Education Focused**: Perfect for training and educational purposes

## ğŸ› ï¸ Technology Stack

### **Backend**
- **Flask** - Python web framework for server-side processing
- **Socket.IO** - Real-time bidirectional communication
- **OpenCV** - Computer vision and image processing
- **NumPy** - Numerical computing for medical data

### **Frontend**
- **React.js** - Modern UI framework
- **Three.js** - 3D graphics and WebGL rendering
- **WebGL** - Hardware-accelerated graphics
- **CSS3** - Responsive styling and animations

### **AI & Computer Vision**
- **MediaPipe** - Hand tracking and gesture recognition
- **Machine Learning** - Intelligent model processing

### **Medical Imaging**
- **NIfTI Support** - Neuroimaging Informatics Technology Initiative format
- **PLY Conversion** - Polygon file format for 3D models
- **DICOM Compatible** - Medical imaging standard support

## ğŸš€ Getting Started

### Prerequisites

- **Python 3.8+** with pip
- **Node.js 16+** with npm
- **Modern browser** with WebGL support
- **Webcam** (for gesture controls)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/YOUR-USERNAME/VitalViz-MRI.git
   cd VitalViz-MRI
   ```

2. **Backend Setup**
   ```bash
   # Create virtual environment
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   
   # Install Python dependencies
   pip install -r requirements.txt
   ```

3. **Frontend Setup**
   ```bash
   # Navigate to frontend directory
   cd frontend
   
   # Install Node.js dependencies
   npm install
   ```

4. **Environment Configuration**
   ```bash
   # Copy environment template
   cp .env.example .env
   
   # Update configuration values
   # Add your API keys and settings
   ```

### Running the Application

1. **Start the Backend Server**
   ```bash
   # From project root
   python app.py
   # Server runs on http://localhost:5000
   ```

2. **Start the Frontend**
   ```bash
   # In a new terminal, from frontend directory
   npm start
   # Application opens at http://localhost:3000
   ```

3. **Access VR Mode**
   - Ensure VR headset is connected
   - Enable WebXR in your browser
   - Click "Enter VR" in the application

## ğŸ“ Project Structure

```
VitalViz-MRI/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                 # Flask application entry point
â”‚   â”œâ”€â”€ routes/                # API routes and endpoints
â”‚   â”œâ”€â”€ models/                # Data models and processing
â”‚   â”œâ”€â”€ utils/                 # Utility functions
â”‚   â””â”€â”€ medical_processing/    # Medical imaging handlers
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/        # React components
â”‚   â”‚   â”œâ”€â”€ pages/             # Application pages
â”‚   â”‚   â”œâ”€â”€ services/          # API services
â”‚   â”‚   â”œâ”€â”€ utils/             # Helper functions
â”‚   â”‚   â””â”€â”€ assets/            # Static assets
â”‚   â”œâ”€â”€ public/                # Public files
â”‚   â””â”€â”€ package.json           # Node.js dependencies
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ sample_models/         # Example brain models
â”‚   â””â”€â”€ converted/             # Processed .ply files
â”œâ”€â”€ docs/                      # Documentation
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                  # Project documentation
```

## ğŸ¯ Usage Guide

### **Loading Medical Data**
1. **Upload .nii files** through the web interface
2. **Wait for conversion** to .ply format
3. **Select viewing mode** (VR or Traditional 3D)

### **Navigation Controls**
- **Mouse/Touch**: Rotate, zoom, and pan the 3D model
- **Keyboard**: Arrow keys for precise movements
- **Gestures**: Use hand movements for VR interaction
- **VR Controllers**: Native VR headset controls

### **Gesture Commands**
- **Point**: Select specific brain regions
- **Pinch**: Zoom in/out on areas of interest
- **Swipe**: Rotate model view
- **Open Palm**: Reset to default view

## ğŸ¥ Medical Applications

### **Educational Use Cases**
- **Medical School Training**: Interactive anatomy lessons
- **Residency Programs**: Advanced neuroimaging education
- **Patient Consultation**: Visual explanation of conditions
- **Research Visualization**: Present findings in 3D format

### **Supported Medical Data**
- **MRI Brain Scans**: Structural and functional imaging
- **CT Scans**: Cross-sectional brain imaging
- **fMRI Data**: Functional magnetic resonance imaging
- **DTI**: Diffusion tensor imaging visualization

## ğŸ† Hackathon Project

This project was developed during a hackathon focused on **Healthcare Innovation & VR Technology**:

- **Team Size**: 4 developers
- **Development Time**: 24 hours
- **Achievement**: Won the emerging tech award
- **Focus**: Bridging healthcare and cutting-edge technology

### **Team Contributions**
- **Medical Data Processing**: Converting neuroimaging files
- **VR Implementation**: Creating immersive viewing experience
- **Gesture Recognition**: Implementing hand tracking controls
- **UI/UX Design**: Intuitive medical professional interface

## ğŸ”§ API Documentation

### **Medical Data Endpoints**
```bash
POST /api/upload-nii        # Upload .nii medical files
GET  /api/models            # List available brain models
GET  /api/convert/:id       # Convert specific model to .ply
POST /api/process-gesture   # Process gesture commands
```

### **Real-time Features**
- **WebSocket Events**: Live model updates
- **Gesture Streaming**: Real-time hand tracking
- **Progress Updates**: File conversion status

## ğŸ¨ Customization

### **Adding New Medical Formats**
1. Create parser in `medical_processing/`
2. Update conversion pipeline
3. Add format detection logic

### **Extending VR Features**
1. Implement new gesture commands
2. Add haptic feedback support
3. Create collaborative viewing modes

## ğŸ¤ Contributing

We welcome contributions from the medical and developer communities!

### **How to Contribute**
1. **Fork the repository**
2. **Create feature branch**
   ```bash
   git checkout -b feature/medical-enhancement
   ```
3. **Implement your changes**
4. **Add tests** for medical data processing
5. **Submit pull request**

### **Contribution Areas**
- [ ] Additional medical file format support
- [ ] Enhanced VR interactions
- [ ] Performance optimizations
- [ ] Medical accuracy improvements
- [ ] Accessibility features

## ğŸ§ª Testing

### **Run Tests**
```bash
# Backend tests
python -m pytest tests/

# Frontend tests
cd frontend && npm test

# Medical data validation
python tests/test_medical_processing.py
```

### **Testing Guidelines**
- Test with various .nii file formats
- Validate 3D model conversion accuracy
- Ensure VR compatibility across devices
- Verify gesture recognition reliability

## ğŸš€ Deployment

### **Production Setup**
```bash
# Build frontend for production
cd frontend && npm run build

# Set up production environment
export FLASK_ENV=production

# Deploy to cloud platform
# (Instructions vary by platform)
```

### **Recommended Platforms**
- **Backend**: AWS EC2, Google Cloud, Heroku
- **Frontend**: Netlify, Vercel, AWS S3
- **Database**: PostgreSQL, MongoDB Atlas

## ğŸ“Š Performance Metrics

- **Model Loading**: < 3 seconds for standard brain models
- **Gesture Response**: < 100ms latency
- **VR Frame Rate**: 60+ FPS in optimized mode
- **File Conversion**: 30-60 seconds for typical .nii files

## ğŸ”’ Security & Privacy

- **Medical Data Protection**: HIPAA-compliant data handling
- **Secure File Upload**: Encrypted transmission
- **Data Retention**: Configurable retention policies
- **Access Control**: Role-based permissions


## ğŸ™ Acknowledgments

- **Medical Imaging Community** for neuroimaging standards
- **VR Development Community** for WebXR advancement
- **Open Source Contributors** for foundational libraries
- **Healthcare Professionals** for domain expertise and feedback
- **Hackathon Organizers** for providing the platform to innovate

## ğŸ”— Related Projects

- [Medical Imaging Libraries](link-to-related-projects)
- [VR Healthcare Applications](link-to-related-projects)
- [Three.js Medical Visualization](link-to-related-projects)

***

**Revolutionizing Medical Education Through Virtual Reality** ğŸ¥

*Empowering healthcare professionals with cutting-edge visualization technology* âœ¨
